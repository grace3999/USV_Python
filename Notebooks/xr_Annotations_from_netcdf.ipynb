{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from skimage import util\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data frame of annotation info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Animal</th>\n",
       "      <th>Group</th>\n",
       "      <th>Session</th>\n",
       "      <th>Begin Time (s)</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>Begin Time (s)_1000</th>\n",
       "      <th>time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>376.574455</td>\n",
       "      <td>low slug</td>\n",
       "      <td>376574.45450</td>\n",
       "      <td>376560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>46.306579</td>\n",
       "      <td>low slug</td>\n",
       "      <td>46306.57941</td>\n",
       "      <td>46305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>243.272865</td>\n",
       "      <td>low slug</td>\n",
       "      <td>243272.86510</td>\n",
       "      <td>243270.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>149.708324</td>\n",
       "      <td>low slug</td>\n",
       "      <td>149708.32400</td>\n",
       "      <td>149692.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>243.176192</td>\n",
       "      <td>low slug</td>\n",
       "      <td>243176.19170</td>\n",
       "      <td>243157.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Animal  Group  Session  Begin Time (s) Annotation  Begin Time (s)_1000  time_stamp\n",
       "0           0     533      5  CPApair      376.574455   low slug         376574.45450    376560.0\n",
       "1           1     533      5  CPApair       46.306579   low slug          46306.57941     46305.0\n",
       "2           2     533      5  CPApair      243.272865   low slug         243272.86510    243270.0\n",
       "3           3     533      5  CPApair      149.708324   low slug         149708.32400    149692.5\n",
       "4           4     533      5  CPApair      243.176192   low slug         243176.19170    243157.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_path = \"C:/Users/Schindler/Documents/Schindler_Lab/Data/Analysis/Excel files/USV/annot_info_df.csv\"\n",
    "annot_data = pd.read_csv(annot_path)\n",
    "annot_info = pd.DataFrame(data = annot_data)\n",
    "annot_info = annot_info[annot_info['Annotation'] != 'radar']\n",
    "print(annot_info.shape)\n",
    "annot_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find path names for each netcdf file corresponding to wav file that has annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_path = 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/533_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/534_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/535_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/542_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/543_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/554_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/555_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/559_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/600_xr_Dataset.nc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_names = []\n",
    "files = os.listdir(netcdf_path)\n",
    "for file in files: \n",
    "        path_names.append(netcdf_path + \"/\" + file)\n",
    "\n",
    "path_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annot_dataset(path, annot_info, size):\n",
    "    \n",
    "    #get animal name from path\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    print(name)\n",
    "    \n",
    "    #open xarray Dataset\n",
    "    data = xr.open_dataset(path)\n",
    "    print(data['slices'].shape)\n",
    "    \n",
    "    #get time_stamps of animal's annotations, select slices and save\n",
    "    yes = annot_info[annot_info['Animal'] ==  int(name)]['time_stamp'].sort_values().values\n",
    "    data_yes = data.sel(slices = yes)\n",
    "    \n",
    "    #get slice indexs (e.g. time_stamps) that are not annotations, select slices and save\n",
    "    slice_indexes = data['slices'].values\n",
    "    no = np.setdiff1d(slice_indexes,yes)\n",
    "    print(yes.shape[0] + no.shape[0])\n",
    "    no_short = np.random.choice(no, size, replace=False)\n",
    "    data_no = data.sel(slices = no_short)\n",
    "    \n",
    "    return data_yes, data_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_purity(Dataset):    \n",
    "    spec_purs = []\n",
    "    \n",
    "    for value in Dataset['slices'].values:\n",
    "        spec_pur = stats.gmean(Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values, axis = None) / Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values.mean()\n",
    "        \n",
    "        spec_purs.append(spec_pur)\n",
    "        \n",
    "    return spec_purs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_centroids(Dataset):\n",
    "    spec_centroids = []\n",
    "    freq_array = Dataset['freq'].values\n",
    "    \n",
    "    for value in Dataset['slices'].values:  \n",
    "        mag_array = Dataset['__xarray_dataarray_variable__'].sel(slices=value).max(dim = 'times').values\n",
    "\n",
    "        freq_mag_sum = sum(freq_array*mag_array)\n",
    "        mag_sum = sum(mag_array)\n",
    "\n",
    "        spec_cent = freq_mag_sum/mag_sum\n",
    "            \n",
    "        spec_centroids.append(spec_cent)\n",
    "        \n",
    "    return spec_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533\n",
      "533\n",
      "(26666,)\n",
      "26666\n",
      "534\n",
      "534\n",
      "(26666,)\n",
      "26666\n",
      "535\n",
      "535\n",
      "(26666,)\n",
      "26666\n",
      "542\n",
      "542\n",
      "(26666,)\n",
      "26666\n",
      "543\n",
      "543\n",
      "(26666,)\n",
      "26666\n",
      "554\n",
      "554\n",
      "(26666,)\n",
      "26666\n",
      "555\n",
      "555\n",
      "(26666,)\n",
      "26666\n",
      "559\n",
      "559\n",
      "(26666,)\n",
      "26666\n",
      "600\n",
      "600\n",
      "(13511,)\n",
      "13511\n",
      "(1084, 7)\n"
     ]
    }
   ],
   "source": [
    "annot_features_yes = pd.DataFrame()\n",
    "annot_features_no = pd.DataFrame()\n",
    "\n",
    "for path in path_names:\n",
    "    \n",
    "    #get animal name from path\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    print(name)\n",
    "    \n",
    "    #create datasets of slices of known annotations and a random selection of noise\n",
    "    data_yes, data_no = create_annot_dataset(path, annot_info, 100)\n",
    "    \n",
    "    #compute power sum\n",
    "    yes_sums = data_yes.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
    "    no_sums = data_no.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
    "    \n",
    "    #compute spectral purity\n",
    "    yes_spec_purs = compute_spectral_purity(data_yes)\n",
    "    no_spec_purs = compute_spectral_purity(data_no)\n",
    "    \n",
    "    #compute spectral centroid\n",
    "    yes_spec_cents = compute_spectral_centroids(data_yes)\n",
    "    no_spec_cents = compute_spectral_centroids(data_no)\n",
    "\n",
    "    #add computed features to exisiting dataframe of known annotations\n",
    "    annot_yes = annot_info[annot_info['Animal'] == int(name)].sort_values(by=['time_stamp'])\n",
    "    annot_yes['power_sum'] = yes_sums\n",
    "    annot_yes['spec_pur'] = yes_spec_purs\n",
    "    annot_yes['spec_cent'] = yes_spec_cents\n",
    "    \n",
    "    #create and fill dataframe for randomly selected noise slices\n",
    "    annot_no = pd.DataFrame(columns = ['Animal', 'Group', 'Annotation', 'time_stamp', 'power_sum', 'spec_pur'], index = np.arange(0,100))\n",
    "    annot_no['Animal'] = name\n",
    "    annot_no['Group'] = annot_info[annot_info['Animal'] == int(name)]['Group'].iloc[0]\n",
    "    annot_no['Annotation'] = 'rand_noise'\n",
    "    annot_no['time_stamp'] = data_no['slices'].values\n",
    "    annot_no['power_sum'] = no_sums\n",
    "    annot_no['spec_pur'] = no_spec_purs\n",
    "    annot_no['spec_cent'] = no_spec_cents\n",
    "    \n",
    "    annot_features_yes = annot_features_yes.append(annot_yes, ignore_index=True)\n",
    "    annot_features_no = annot_features_no.append(annot_no, ignore_index=True)\n",
    "\n",
    "#create and save combined dataframe of yes and no\n",
    "annot_features_yes.drop(['Unnamed: 0', 'Session', 'Begin Time (s)', 'Begin Time (s)_1000'], axis=1, inplace=True)\n",
    "annot_features_full = pd.concat([annot_features_yes, annot_features_no])\n",
    "print(annot_features_full.shape)\n",
    "\n",
    "annot_features_full.to_csv('annot_features_full.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
