{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from skimage import util\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data frame of annotation info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_path = \"C:/Users/Schindler/Documents/Schindler_Lab/Data/Analysis/Excel files/USV/annot_info_df.csv\"\n",
    "annot_data = pd.read_csv(annot_path)\n",
    "annot_info = pd.DataFrame(data = annot_data)\n",
    "annot_info = annot_info[annot_info['Annotation'] != 'radar']\n",
    "print(annot_info.shape)\n",
    "annot_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find path names for each netcdf file corresponding to wav file that has annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_path = 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/533_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/534_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/535_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/542_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/543_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/554_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/555_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/559_xr_Dataset.nc',\n",
       " 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets/600_xr_Dataset.nc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_names = []\n",
    "files = os.listdir(netcdf_path)\n",
    "for file in files: \n",
    "        path_names.append(netcdf_path + \"/\" + file)\n",
    "\n",
    "path_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annot_dataset(path, annot_info, size):\n",
    "    \n",
    "    #get animal name from path\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    print(name)\n",
    "    \n",
    "    #open xarray Dataset\n",
    "    data = xr.open_dataset(path)\n",
    "    print(data['slices'].shape)\n",
    "    \n",
    "    #get time_stamps of animal's annotations, select slices and save\n",
    "    yes = annot_info[annot_info['Animal'] ==  int(name)]['time_stamp'].sort_values().values\n",
    "    print(yes.shape)\n",
    "    data_yes = data.sel(slices = yes)\n",
    "    \n",
    "    #get slice indexs (e.g. time_stamps) that are not annotations, select slices and save\n",
    "    slice_indexes = data['slices'].values\n",
    "    no = np.setdiff1d(slice_indexes,yes)\n",
    "    print(no.shape)\n",
    "    print(yes.shape[0] + no.shape[0])\n",
    "    no_short = np.random.choice(no, size, replace=False)\n",
    "    data_no = data.sel(slices = no_short)\n",
    "    \n",
    "    return data_yes, data_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533\n",
      "533\n",
      "(26666,)\n",
      "(12,)\n",
      "(26654,)\n",
      "26666\n",
      "534\n",
      "534\n",
      "(26666,)\n",
      "(11,)\n",
      "(26655,)\n",
      "26666\n",
      "535\n",
      "535\n",
      "(26666,)\n",
      "(36,)\n",
      "(26630,)\n",
      "26666\n",
      "542\n",
      "542\n",
      "(26666,)\n",
      "(14,)\n",
      "(26652,)\n",
      "26666\n",
      "543\n",
      "543\n",
      "(26666,)\n",
      "(7,)\n",
      "(26659,)\n",
      "26666\n",
      "554\n",
      "554\n",
      "(26666,)\n",
      "(13,)\n",
      "(26653,)\n",
      "26666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Schindler\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\scipy\\stats\\stats.py:316: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n",
      "C:\\Users\\Schindler\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\ipykernel_launcher.py:24: RuntimeWarning: invalid value encountered in float_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n",
      "555\n",
      "(26666,)\n",
      "(6,)\n",
      "(26660,)\n",
      "26666\n",
      "559\n",
      "559\n",
      "(26666,)\n",
      "(10,)\n",
      "(26656,)\n",
      "26666\n",
      "600\n",
      "600\n",
      "(13511,)\n",
      "(75,)\n",
      "(13436,)\n",
      "13511\n",
      "(1084, 6)\n"
     ]
    }
   ],
   "source": [
    "annot_features_yes = pd.DataFrame()\n",
    "annot_features_no = pd.DataFrame()\n",
    "\n",
    "for path in path_names:\n",
    "    \n",
    "    #get animal name from path\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    print(name)\n",
    "    \n",
    "    #create datasets of slices of known annotations and a random selection of noise\n",
    "    data_yes, data_no = create_annot_dataset(path, annot_info, 100)\n",
    "    \n",
    "    #compute power sum and spectral purity\n",
    "    yes_sums = data_yes.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
    "    no_sums = data_no.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
    "    \n",
    "    yes_spec_purs = []\n",
    "    for value in data_yes['slices'].values:\n",
    "        spec_pur = stats.gmean(data_yes.sel(slices = value)['__xarray_dataarray_variable__'].values, axis = None) / data_yes.sel(slices = value)['__xarray_dataarray_variable__'].values.mean()\n",
    "        yes_spec_purs.append(spec_pur)\n",
    "        \n",
    "    no_spec_purs = []\n",
    "    for value in data_no['slices'].values:\n",
    "        spec_pur = stats.gmean(data_no.sel(slices = value)['__xarray_dataarray_variable__'].values, axis = None) / data_no.sel(slices = value)['__xarray_dataarray_variable__'].values.mean()\n",
    "        no_spec_purs.append(spec_pur)\n",
    "    \n",
    "    #add computed features to exisiting dataframe of known annotations\n",
    "    annot_yes = annot_info[annot_info['Animal'] == int(name)].sort_values(by=['time_stamp'])\n",
    "    annot_yes['power_sum'] = yes_sums\n",
    "    annot_yes['spec_pur'] = yes_spec_purs\n",
    "    \n",
    "    #create and fill dataframe for randomly selected noise slices\n",
    "    annot_no = pd.DataFrame(columns = ['Animal', 'Group', 'Annotation', 'time_stamp', 'power_sum', 'spec_pur'], index = np.arange(0,100))\n",
    "    annot_no['Animal'] = name\n",
    "    annot_no['Group'] = annot_info[annot_info['Animal'] == int(name)]['Group'].iloc[0]\n",
    "    annot_no['Annotation'] = 'rand_noise'\n",
    "    annot_no['time_stamp'] = data_no['slices'].values\n",
    "    annot_no['power_sum'] = no_sums\n",
    "    annot_no['spec_pur'] = no_spec_purs\n",
    "    \n",
    "    annot_features_yes = annot_features_yes.append(annot_yes, ignore_index=True)\n",
    "    annot_features_no = annot_features_no.append(annot_no, ignore_index=True)\n",
    "\n",
    "#create and save combined dataframe of yes and no\n",
    "annot_features_yes.drop(['Unnamed: 0', 'Session', 'Begin Time (s)', 'Begin Time (s)_1000'], axis=1, inplace=True)\n",
    "annot_features_full = pd.concat([annot_features_yes, annot_features_no])\n",
    "print(annot_features_full.shape)\n",
    "\n",
    "annot_features_full.to_csv('annot_features_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal</th>\n",
       "      <th>Group</th>\n",
       "      <th>Annotation</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>power_sum</th>\n",
       "      <th>spec_pur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>low slug</td>\n",
       "      <td>46305.0</td>\n",
       "      <td>32714.904297</td>\n",
       "      <td>0.368722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>low slug</td>\n",
       "      <td>149692.5</td>\n",
       "      <td>43037.464844</td>\n",
       "      <td>0.306856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>low slug</td>\n",
       "      <td>243157.5</td>\n",
       "      <td>270193.531250</td>\n",
       "      <td>0.062226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>low slug</td>\n",
       "      <td>243270.0</td>\n",
       "      <td>63014.449219</td>\n",
       "      <td>0.232295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>533</td>\n",
       "      <td>5</td>\n",
       "      <td>low multi</td>\n",
       "      <td>295560.0</td>\n",
       "      <td>74933.164062</td>\n",
       "      <td>0.206291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Animal  Group Annotation  time_stamp      power_sum  spec_pur\n",
       "0    533      5   low slug     46305.0   32714.904297  0.368722\n",
       "1    533      5   low slug    149692.5   43037.464844  0.306856\n",
       "2    533      5   low slug    243157.5  270193.531250  0.062226\n",
       "3    533      5   low slug    243270.0   63014.449219  0.232295\n",
       "4    533      5  low multi    295560.0   74933.164062  0.206291"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_features_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
