{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_xr_Annotations_from_netcdf_8features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grace3999/USV_Python/blob/colab/Notebooks/2_xr_Annotations_from_netcdf_8features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "deqrCXk9rI0V",
        "colab_type": "code",
        "outputId": "a88a55f5-e929-4cc4-accd-0a384a4ea61b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "#mount google drive containings required files: 1) csv of annotation features, 2) netcdf files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQy4DI2h2Xkx",
        "colab_type": "code",
        "outputId": "82fd60ab-ca82-4699-e2d4-f271fff58fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install netcdf4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting netcdf4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/71/a9d3ae9b2bb261b4446631fdb4b4409d33767a7e3216735231e0844317fd/netCDF4-1.4.3.2-cp36-cp36m-manylinux1_x86_64.whl (3.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.9MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.14.6)\n",
            "Collecting cftime (from netcdf4)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/64/8ceadda42af3c1b27ee77005807e38c6d77baef28a8f9216b60577fddd71/cftime-1.0.3.4-cp36-cp36m-manylinux1_x86_64.whl (305kB)\n",
            "\u001b[K    100% |████████████████████████████████| 307kB 21.6MB/s \n",
            "\u001b[?25hInstalling collected packages: cftime, netcdf4\n",
            "Successfully installed cftime-1.0.3.4 netcdf4-1.4.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yt2j-aLYrGyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from scipy import stats\n",
        "import xarray as xr\n",
        "\n",
        "#visualizing results\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWxUzYD-IgJx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#may need to be updated based on file naming scheme\n",
        "def get_file_info(path, order):\n",
        "    \"\"\"takes in a file path for annotation selections table and finds the animal_number and session and saves each accordingly. \n",
        "    each file should be named with animal number and exp (e.g. 100_CPA.Table.1.selections)\"\"\"\n",
        "    \n",
        "    if order == 'animal':\n",
        "      animal_number, session = re.split('_|-', path.split('/')[-1].split('.')[0])[0:2]\n",
        "    else:\n",
        "      session, animal_number = re.split('_|-', path.split('/')[-1].split('.')[0])[0:2] \n",
        "    \n",
        "    print(animal_number, session)\n",
        "    \n",
        "    return animal_number, session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ci9n5RHOrGzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#need to be updated with animal naming scheme (e.g. int(animal_number) vs animal_number)\n",
        "def create_annot_dataset(path, animal_number, session, annot_data, size_random):\n",
        "    \"\"\"takes in path of netcdf file (created using notebook 1) and corresponding annotations (created using notebook 0)\n",
        "    and creates a new data set of only slices correspondingn to annotations (and random noise if set to True)\"\"\"\n",
        "    \n",
        "    #open xarray Dataset\n",
        "    data = xr.open_dataset(path)\n",
        "    print(data['slices'].shape)\n",
        "    \n",
        "    #get time_stamps of animal's annotations, select slices and save\n",
        "    yes = annot_data[(annot_data['animal_number'] ==  int(animal_number)) & (annot_data['session'] ==  session)]['time_stamp'].sort_values().values\n",
        "    data_yes = data.sel(slices = yes)\n",
        "    \n",
        "    #get slice indexs (e.g. time_stamps) that are not annotations, select slices and save\n",
        "    slice_indexes = data['slices'].values\n",
        "    no = np.setdiff1d(slice_indexes,yes)\n",
        "    print(yes.shape[0] + no.shape[0])\n",
        "    no_short = np.random.choice(no, size_random, replace=False)\n",
        "    data_no = data.sel(slices = no_short)\n",
        "    \n",
        "    return data_yes, data_no"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ph1QOF4-rGzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_spectral_features(Dataset):\n",
        "    \"\"\"takes in netcdf dataset and computes 8 features\"\"\"\n",
        "    \n",
        "    spec_power = []\n",
        "    spec_purs = []\n",
        "    spec_centroid = []\n",
        "    spec_spread = []\n",
        "    spec_skewness = []\n",
        "    spec_kurtosis = []\n",
        "    spec_slope = []\n",
        "    spec_roll_off = []\n",
        "    \n",
        "    freq_array = Dataset['freq'].values\n",
        "    \n",
        "    #compute power sum using groupby\n",
        "    spec_power = Dataset.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
        "    \n",
        "    #compute other features for each slice individually\n",
        "    for value in Dataset['slices'].values:\n",
        "        \n",
        "        spec_pur = stats.gmean(Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values, axis = None) / Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values.mean()\n",
        "        \n",
        "        mag_array = Dataset['__xarray_dataarray_variable__'].sel(slices=value).sum(dim = 'times').values\n",
        "        mag_probs = mag_array/sum(mag_array)\n",
        "        freq_mag = freq_array*mag_probs\n",
        "        \n",
        "        spec_cent = sum(freq_mag)\n",
        "        spec_spr = np.var(freq_mag)\n",
        "        spec_skew = stats.skew(freq_mag)\n",
        "        spec_kurt = stats.kurtosis(freq_mag)\n",
        "        slope, intercept, r_value, p_value, std_err = stats.linregress(freq_array, freq_mag)\n",
        "        spec_ro = .95*sum(freq_mag)\n",
        "        \n",
        "        spec_purs.append(spec_pur)\n",
        "        spec_centroid.append(spec_cent)\n",
        "        spec_spread.append(spec_spr)\n",
        "        spec_skewness.append(spec_skew)\n",
        "        spec_kurtosis.append(spec_kurt)\n",
        "        spec_slope.append(slope)\n",
        "        spec_roll_off.append(spec_ro)\n",
        "        \n",
        "    return spec_power, spec_purs, spec_centroid, spec_spread, spec_skewness, spec_kurtosis, spec_slope, spec_roll_off"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivtFcsJdrGzk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#need to be updated with animal naming scheme (e.g. int(animal_number) vs animal_number)\n",
        "def create_annotation_slice_features(path, order, annot_data, size_random):\n",
        "    \"\"\"takes in path of netcdf file (created using notebook 1), corresponding annotations (created using notebook 0),\n",
        "    and size desired for random slicecs from each file.\n",
        "    uses create_annot_dataset and compute_spectral_features functions to create a new data set of computed features\n",
        "    for only slices correspondingn to annotations and random noise\"\"\"\n",
        "    \n",
        "    \n",
        "    animal_number, session = get_file_info(path, order)\n",
        "\n",
        "    print(animal_number, session)\n",
        "    \n",
        "    #create datasets of slices of known annotations and a random selection of noise\n",
        "    data_yes, data_no = create_annot_dataset(path, animal_number, session, annot_data, size_random)\n",
        "    \n",
        "    #compute spectral features\n",
        "    yes_spec_power, yes_spec_purs, yes_spec_centroid, yes_spec_spread, yes_spec_skewness, yes_spec_kurtosis, yes_spec_slope, yes_spec_roll_off = compute_spectral_features(data_yes)\n",
        "    no_spec_power, no_spec_purs, no_spec_centroid, no_spec_spread, no_spec_skewness, no_spec_kurtosis, no_spec_slope, no_spec_roll_off = compute_spectral_features(data_no)\n",
        "\n",
        "    #add computed features to exisiting dataframe of known annotations\n",
        "    annot_yes = annot_data[(annot_data['animal_number'] ==  int(animal_number)) & (annot_data['session'] ==  session)].sort_values(by=['time_stamp'])\n",
        "    annot_yes['power_sum'] = yes_spec_power\n",
        "    annot_yes['spec_pur'] = yes_spec_purs\n",
        "    annot_yes['spec_cent'] = yes_spec_centroid\n",
        "    annot_yes['spec_spread'] = yes_spec_spread\n",
        "    annot_yes['spec_skew'] = yes_spec_skewness\n",
        "    annot_yes['spec_kurt'] = yes_spec_kurtosis\n",
        "    annot_yes['spec_slope'] = yes_spec_slope\n",
        "    annot_yes['spec_roll'] = yes_spec_roll_off\n",
        "    \n",
        "    #create and fill dataframe for randomly selected noise slices\n",
        "    annot_no = pd.DataFrame(columns = ['animal_number', 'session', 'time_stamp', 'Annotation'], index = np.arange(0,size_random))\n",
        "    annot_no['animal_number'] = animal_number\n",
        "    annot_no['session'] = session\n",
        "    annot_no['Annotation'] = 'rand_noise'\n",
        "    annot_no['time_stamp'] = data_no['slices'].values\n",
        "    annot_no['power_sum'] = no_spec_power\n",
        "    annot_no['spec_pur'] = no_spec_purs\n",
        "    annot_no['spec_cent'] = no_spec_centroid\n",
        "    annot_no['spec_spread'] = no_spec_spread\n",
        "    annot_no['spec_skew'] = no_spec_skewness\n",
        "    annot_no['spec_kurt'] = no_spec_kurtosis\n",
        "    annot_no['spec_slope'] = no_spec_slope\n",
        "    annot_no['spec_roll'] = no_spec_roll_off\n",
        "    \n",
        "    return annot_yes, annot_no "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlRo_PFFrGzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create data frame of annotation info"
      ]
    },
    {
      "metadata": {
        "id": "BWxUEmy_rGzr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "annot_path_cage = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_homecage.csv'\n",
        "annot_path_CPApost = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_CPA.csv'\n",
        "annot_path_pain = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_pain.csv'\n",
        "\n",
        "annot_paths = [annot_path_CPApost, annot_path_cage, annot_path_pain]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ks2ASEkirGzx",
        "colab_type": "code",
        "outputId": "0169ef51-54b7-4e42-9c41-18709c747df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "cell_type": "code",
      "source": [
        "annot_data = pd.DataFrame()\n",
        "\n",
        "for path in annot_paths:\n",
        "    annot = pd.read_csv(path)\n",
        "    annot = pd.DataFrame(data = annot)\n",
        "    if 'radar' in annot['Annotation'].values:\n",
        "      annot = annot[annot['Annotation'] != 'radar']\n",
        "    if True in pd.isna(annot['Annotation']).values:\n",
        "      annot['Annotation'] = ['BBC'] * annot['Annotation'].shape[0]\n",
        "    \n",
        "    print(annot.shape)\n",
        "    print(annot.Annotation.value_counts())\n",
        "    \n",
        "    annot_data = annot_data.append(annot)\n",
        "\n",
        "print(annot_data.shape)\n",
        "annot_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 6)\n",
            "low slug      48\n",
            "low multi     20\n",
            "bbc           15\n",
            "high slug      6\n",
            "high multi     1\n",
            "Name: Annotation, dtype: int64\n",
            "(69, 6)\n",
            "bbc           30\n",
            "high slug     21\n",
            "low slug      12\n",
            "high multi     3\n",
            "low multi      3\n",
            "Name: Annotation, dtype: int64\n",
            "(178, 6)\n",
            "BBC    178\n",
            "Name: Annotation, dtype: int64\n",
            "(337, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>animal_number</th>\n",
              "      <th>session</th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>Annotation</th>\n",
              "      <th>High Freq (Hz)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>46305.0</td>\n",
              "      <td>low slug</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>149692.5</td>\n",
              "      <td>low slug</td>\n",
              "      <td>16074.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>243157.5</td>\n",
              "      <td>low slug</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>295560.0</td>\n",
              "      <td>low multi</td>\n",
              "      <td>27489.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>141</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>376560.0</td>\n",
              "      <td>low slug</td>\n",
              "      <td>9940.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0 animal_number  session  time_stamp Annotation  High Freq (Hz)\n",
              "0             0           533  CPApair     46305.0   low slug         16500.0\n",
              "2             2           533  CPApair    149692.5   low slug         16074.5\n",
              "3             3           533  CPApair    243157.5   low slug         16500.0\n",
              "4             4           533  CPApair    295560.0  low multi         27489.6\n",
              "141         141           533  CPApair    376560.0   low slug          9940.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "6DAhrRKCrGz2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Find path names for each netcdf file corresponding to wav file that has annotated data"
      ]
    },
    {
      "metadata": {
        "id": "RqrhyDzlrGz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "netcdf_path_fear = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear'\n",
        "\n",
        "netcdf_path_pain = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgYEAG9BrGz7",
        "colab_type": "code",
        "outputId": "925886f9-3f40-4a0e-a57f-0f9e0919ab34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "path = netcdf_path_fear\n",
        "\n",
        "path_names = []\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "  path_names.append(path + \"/\" + file)\n",
        "\n",
        "print(len(path_names))\n",
        "path_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/533_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/559_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/555_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/554_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/543_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/542_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/535_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/534_CPApair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/529_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/527_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/556_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/553_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/552_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/541_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/540_cagepair_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear/557_cagepair_xr_Dataset.nc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Wh73dobhnmRw",
        "colab_type": "code",
        "outputId": "7cd51e54-e442-4ffc-f602-7e9b60b57100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1241
        }
      },
      "cell_type": "code",
      "source": [
        "order = 'animal'\n",
        "size_random = 100\n",
        "session_name = 'fear'\n",
        "save_path = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/feature_data_frames'\n",
        "\n",
        "annot_features_yes = pd.DataFrame()\n",
        "annot_features_no = pd.DataFrame()\n",
        "\n",
        "for path in path_names:\n",
        "    \n",
        "    annot_yes, annot_no = create_annotation_slice_features(path, order, annot_data, size_random)\n",
        "    \n",
        "    annot_features_yes = annot_features_yes.append(annot_yes, ignore_index=True)\n",
        "    annot_features_no = annot_features_no.append(annot_no, ignore_index=True)\n",
        "\n",
        "#create and save combined dataframe of yes and no\n",
        "annot_features_yes.drop(['Unnamed: 0', 'High Freq (Hz)'], axis=1, inplace=True)\n",
        "annot_features_full = pd.concat([annot_features_yes, annot_features_no])\n",
        "print(annot_features_full.shape)\n",
        "print(annot_features_full.Annotation.value_counts())\n",
        "\n",
        "annot_features_full.to_csv(str(save_path + '/annot_8features_100noise_' + session_name + '_.csv'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "533 CPApair\n",
            "533 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "559 CPApair\n",
            "559 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "555 CPApair\n",
            "555 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "554 CPApair\n",
            "554 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "543 CPApair\n",
            "543 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "542 CPApair\n",
            "542 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "535 CPApair\n",
            "535 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "534 CPApair\n",
            "534 CPApair\n",
            "(26666,)\n",
            "26666\n",
            "529 cagepair\n",
            "529 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "527 cagepair\n",
            "527 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "556 cagepair\n",
            "556 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "553 cagepair\n",
            "553 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "552 cagepair\n",
            "552 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "541 cagepair\n",
            "541 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "540 cagepair\n",
            "540 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "557 cagepair\n",
            "557 cagepair\n",
            "(26666,)\n",
            "26666\n",
            "(1759, 12)\n",
            "rand_noise    1600\n",
            "low slug        60\n",
            "bbc             45\n",
            "high slug       27\n",
            "low multi       23\n",
            "high multi       4\n",
            "Name: Annotation, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}