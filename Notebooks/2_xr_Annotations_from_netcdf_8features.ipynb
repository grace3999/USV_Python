{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_xr_Annotations_from_netcdf_8features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grace3999/USV_Python/blob/colab/Notebooks/2_xr_Annotations_from_netcdf_8features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deqrCXk9rI0V",
        "colab_type": "code",
        "outputId": "1fba7c7c-aa0b-4b07-fc6d-aafad8209d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#mount google drive containings required files: 1) csv of annotation features, 2) netcdf files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQy4DI2h2Xkx",
        "colab_type": "code",
        "outputId": "d4572477-5eaa-4963-e286-0ebfc8ba5ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "!pip install netcdf4"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.6/dist-packages (1.5.1.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.16.4)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.0.3.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt2j-aLYrGyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from scipy import stats\n",
        "import xarray as xr\n",
        "\n",
        "#visualizing results\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWxUzYD-IgJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#may need to be updated based on file naming scheme\n",
        "def get_file_info(path, order):\n",
        "    \"\"\"takes in a file path for annotation selections table and finds the animal_number and session and saves each accordingly. \n",
        "    each file should be named with animal number and exp (e.g. 100_CPA.Table.1.selections)\"\"\"\n",
        "    \n",
        "    if order == 'animal':\n",
        "      animal_number, session = re.split('_|-', path.split('/')[-1].split('.')[0])[0:2]\n",
        "    else:\n",
        "      session, animal_number = re.split('_|-', path.split('/')[-1].split('.')[0])[0:2] \n",
        "    \n",
        "    print(animal_number, session)\n",
        "    \n",
        "    return animal_number, session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci9n5RHOrGzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#need to be updated with animal naming scheme (e.g. int(animal_number) vs animal_number)\n",
        "def create_annot_dataset(path, animal_number, session, annot_data, size_random):\n",
        "    \"\"\"takes in path of netcdf file (created using notebook 1) and corresponding annotations (created using notebook 0)\n",
        "    and creates a new data set of only slices correspondingn to annotations (and random noise if set to True)\"\"\"\n",
        "    \n",
        "    #open xarray Dataset\n",
        "    data = xr.open_dataset(path)\n",
        "    print(data['slices'].shape)\n",
        "    \n",
        "    #get time_stamps of animal's annotations, select slices and save\n",
        "    yes = annot_data[(annot_data['animal_number'] ==  int(animal_number)) & (annot_data['session'] ==  session)]['time_stamp'].sort_values().values\n",
        "    data_yes = data.sel(slices = yes)\n",
        "    \n",
        "    #get slice indexs (e.g. time_stamps) that are not annotations, select slices and save\n",
        "    slice_indexes = data['slices'].values\n",
        "    no = np.setdiff1d(slice_indexes,yes)\n",
        "    print(yes.shape[0] + no.shape[0])\n",
        "    no_short = np.random.choice(no, size_random, replace=False)\n",
        "    data_no = data.sel(slices = no_short)\n",
        "    \n",
        "    return data_yes, data_no"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph1QOF4-rGzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_spectral_features(Dataset):\n",
        "    \"\"\"takes in netcdf dataset and computes 8 features\"\"\"\n",
        "    \n",
        "    spec_power = []\n",
        "    spec_purs = []\n",
        "    spec_centroid = []\n",
        "    spec_spread = []\n",
        "    spec_skewness = []\n",
        "    spec_kurtosis = []\n",
        "    spec_slope = []\n",
        "    spec_roll_off = []\n",
        "    \n",
        "    freq_array = Dataset['freq'].values\n",
        "    \n",
        "    #compute power sum using groupby\n",
        "    spec_power = Dataset.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
        "    \n",
        "    #compute other features for each slice individually\n",
        "    for value in Dataset['slices'].values:\n",
        "        \n",
        "        spec_pur = stats.gmean(Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values, axis = None) / Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values.mean()\n",
        "        \n",
        "        mag_array = Dataset['__xarray_dataarray_variable__'].sel(slices=value).sum(dim = 'times').values\n",
        "        mag_probs = mag_array/sum(mag_array)\n",
        "        freq_mag = freq_array*mag_probs\n",
        "        \n",
        "        spec_cent = sum(freq_mag)\n",
        "        spec_spr = np.var(freq_mag)\n",
        "        spec_skew = stats.skew(freq_mag)\n",
        "        spec_kurt = stats.kurtosis(freq_mag)\n",
        "        slope, intercept, r_value, p_value, std_err = stats.linregress(freq_array, freq_mag)\n",
        "        spec_ro = .95*sum(freq_mag)\n",
        "        \n",
        "        spec_purs.append(spec_pur)\n",
        "        spec_centroid.append(spec_cent)\n",
        "        spec_spread.append(spec_spr)\n",
        "        spec_skewness.append(spec_skew)\n",
        "        spec_kurtosis.append(spec_kurt)\n",
        "        spec_slope.append(slope)\n",
        "        spec_roll_off.append(spec_ro)\n",
        "        \n",
        "    return spec_power, spec_purs, spec_centroid, spec_spread, spec_skewness, spec_kurtosis, spec_slope, spec_roll_off"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivtFcsJdrGzk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#need to be updated with animal naming scheme (e.g. int(animal_number) vs animal_number)\n",
        "def create_annotation_slice_features(path, order, annot_data, size_random):\n",
        "    \"\"\"takes in path of netcdf file (created using notebook 1), corresponding annotations (created using notebook 0),\n",
        "    and size desired for random slicecs from each file.\n",
        "    uses create_annot_dataset and compute_spectral_features functions to create a new data set of computed features\n",
        "    for only slices correspondingn to annotations and random noise\"\"\"\n",
        "    \n",
        "    \n",
        "    animal_number, session = get_file_info(path, order)\n",
        "\n",
        "    print(animal_number, session)\n",
        "    \n",
        "    #create datasets of slices of known annotations and a random selection of noise\n",
        "    data_yes, data_no = create_annot_dataset(path, animal_number, session, annot_data, size_random)\n",
        "    \n",
        "    #compute spectral features\n",
        "    yes_spec_power, yes_spec_purs, yes_spec_centroid, yes_spec_spread, yes_spec_skewness, yes_spec_kurtosis, yes_spec_slope, yes_spec_roll_off = compute_spectral_features(data_yes)\n",
        "    no_spec_power, no_spec_purs, no_spec_centroid, no_spec_spread, no_spec_skewness, no_spec_kurtosis, no_spec_slope, no_spec_roll_off = compute_spectral_features(data_no)\n",
        "\n",
        "    #add computed features to exisiting dataframe of known annotations\n",
        "    annot_yes = annot_data[(annot_data['animal_number'] ==  int(animal_number)) & (annot_data['session'] ==  session)].sort_values(by=['time_stamp'])\n",
        "    annot_yes['power_sum'] = yes_spec_power\n",
        "    annot_yes['spec_pur'] = yes_spec_purs\n",
        "    annot_yes['spec_cent'] = yes_spec_centroid\n",
        "    annot_yes['spec_spread'] = yes_spec_spread\n",
        "    annot_yes['spec_skew'] = yes_spec_skewness\n",
        "    annot_yes['spec_kurt'] = yes_spec_kurtosis\n",
        "    annot_yes['spec_slope'] = yes_spec_slope\n",
        "    annot_yes['spec_roll'] = yes_spec_roll_off\n",
        "    \n",
        "    #create and fill dataframe for randomly selected noise slices\n",
        "    annot_no = pd.DataFrame(columns = ['animal_number', 'session', 'time_stamp', 'Annotation'], index = np.arange(0,size_random))\n",
        "    annot_no['animal_number'] = animal_number\n",
        "    annot_no['session'] = session\n",
        "    annot_no['Annotation'] = 'rand_noise'\n",
        "    annot_no['time_stamp'] = data_no['slices'].values\n",
        "    annot_no['power_sum'] = no_spec_power\n",
        "    annot_no['spec_pur'] = no_spec_purs\n",
        "    annot_no['spec_cent'] = no_spec_centroid\n",
        "    annot_no['spec_spread'] = no_spec_spread\n",
        "    annot_no['spec_skew'] = no_spec_skewness\n",
        "    annot_no['spec_kurt'] = no_spec_kurtosis\n",
        "    annot_no['spec_slope'] = no_spec_slope\n",
        "    annot_no['spec_roll'] = no_spec_roll_off\n",
        "    \n",
        "    return annot_yes, annot_no "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlRo_PFFrGzp",
        "colab_type": "text"
      },
      "source": [
        "Create data frame of annotation info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWxUEmy_rGzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "annot_path_cFos_CPA = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_CPApost_cFos_CPA.csv'\n",
        "annot_path_cFos_neutral = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_neutral_cFos_neutral.csv'\n",
        "\n",
        "annot_path_PETr1_CPA = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_CPApost_PETr1_CPA.csv'\n",
        "\n",
        "annot_path_round2_CPA = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_CPApost_round2_CPA.csv'\n",
        "annot_path_round2_neutral = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_neutral_round2_neutral.csv'\n",
        "\n",
        "annot_paths = [annot_path_cFos_CPA, annot_path_cFos_neutral, annot_path_PETr1_CPA, annot_path_round2_CPA, annot_path_round2_neutral]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks2ASEkirGzx",
        "colab_type": "code",
        "outputId": "ee90923a-d055-4c4a-8ca8-98a7c3de9ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "annot_data = pd.DataFrame()\n",
        "\n",
        "for path in annot_paths:\n",
        "    annot = pd.read_csv(path)\n",
        "    annot = pd.DataFrame(data = annot)\n",
        "    if 'radar' in annot['Annotation'].values:\n",
        "      annot = annot[annot['Annotation'] != 'radar']\n",
        "    if True in pd.isna(annot['Annotation']).values:\n",
        "      annot['Annotation'] = ['BBC'] * annot['Annotation'].shape[0]\n",
        "    \n",
        "    print(annot.shape)\n",
        "    print(annot.Annotation.value_counts())\n",
        "    \n",
        "    annot_data = annot_data.append(annot)\n",
        "\n",
        "print(annot_data.shape)\n",
        "annot_data.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 6)\n",
            "low           48\n",
            "low multi     20\n",
            "bbc           15\n",
            "high           6\n",
            "high multi     1\n",
            "Name: Annotation, dtype: int64\n",
            "(69, 6)\n",
            "bbc           30\n",
            "high          21\n",
            "low           12\n",
            "high multi     3\n",
            "low multi      3\n",
            "Name: Annotation, dtype: int64\n",
            "(154, 6)\n",
            "low            87\n",
            "low multi      25\n",
            "low complex    18\n",
            "high           12\n",
            "bbc            11\n",
            "high multi      1\n",
            "Name: Annotation, dtype: int64\n",
            "(81, 6)\n",
            "BBC    81\n",
            "Name: Annotation, dtype: int64\n",
            "(34, 6)\n",
            "low            14\n",
            "high            9\n",
            "low complex     5\n",
            "bbc             3\n",
            "low multi       2\n",
            "low             1\n",
            "Name: Annotation, dtype: int64\n",
            "(428, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>animal_number</th>\n",
              "      <th>session</th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>Annotation</th>\n",
              "      <th>High Freq (Hz)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApost</td>\n",
              "      <td>46305.0</td>\n",
              "      <td>low</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApost</td>\n",
              "      <td>149692.5</td>\n",
              "      <td>low</td>\n",
              "      <td>16074.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApost</td>\n",
              "      <td>243157.5</td>\n",
              "      <td>low</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApost</td>\n",
              "      <td>295560.0</td>\n",
              "      <td>low multi</td>\n",
              "      <td>27489.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>141</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApost</td>\n",
              "      <td>376560.0</td>\n",
              "      <td>low</td>\n",
              "      <td>9940.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0  animal_number  session  time_stamp Annotation  High Freq (Hz)\n",
              "0             0            533  CPApost     46305.0        low         16500.0\n",
              "2             2            533  CPApost    149692.5        low         16074.5\n",
              "3             3            533  CPApost    243157.5        low         16500.0\n",
              "4             4            533  CPApost    295560.0  low multi         27489.6\n",
              "141         141            533  CPApost    376560.0        low          9940.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DAhrRKCrGz2",
        "colab_type": "text"
      },
      "source": [
        "Find path names for each netcdf file corresponding to wav file that has annotated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqrhyDzlrGz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netcdf_path_CPA = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/CPA'\n",
        "\n",
        "netcdf_path_neutral = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgYEAG9BrGz7",
        "colab_type": "code",
        "outputId": "c625931f-5c37-4e80-8fbf-03266dfbd558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "path = netcdf_path_neutral\n",
        "\n",
        "path_names = []\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "  path_names.append(path + \"/\" + file)\n",
        "\n",
        "print(len(path_names))\n",
        "path_names"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/527_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/529_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/540_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/541_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/552_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/553_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/556_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/557_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/621_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/622_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/624_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/626_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/628_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/629_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/630_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/631_neutral_xr_Dataset.nc',\n",
              " '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/netcdf_files/Neutral/632_neutral_xr_Dataset.nc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh73dobhnmRw",
        "colab_type": "code",
        "outputId": "9e9daf8e-ec3c-43b2-e86a-d8df9bf77a62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "order = 'animal'\n",
        "size_random = 100\n",
        "session_name = 'neutral'\n",
        "save_path = '/content/gdrive/Shared drives/USV_eScience_Incubator/Data/feature_data_frames'\n",
        "\n",
        "annot_features_yes = pd.DataFrame()\n",
        "annot_features_no = pd.DataFrame()\n",
        "\n",
        "for path in path_names:\n",
        "  \n",
        "  annot_yes, annot_no = create_annotation_slice_features(path, order, annot_data, size_random)\n",
        "    \n",
        "  annot_features_yes = annot_features_yes.append(annot_yes, ignore_index=True)\n",
        "  annot_features_no = annot_features_no.append(annot_no, ignore_index=True)\n",
        "\n",
        "#create and save combined dataframe of yes and no\n",
        "annot_features_yes.drop(['Unnamed: 0', 'High Freq (Hz)'], axis=1, inplace=True)\n",
        "annot_features_full = pd.concat([annot_features_yes, annot_features_no])\n",
        "print(annot_features_full.shape)\n",
        "print(annot_features_full.Annotation.value_counts())\n",
        "\n",
        "annot_features_full.to_csv(str(save_path + '/annot_8features_100noise_' + session_name + '_.csv'))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "527 neutral\n",
            "527 neutral\n",
            "(26666,)\n",
            "26666\n",
            "529 neutral\n",
            "529 neutral\n",
            "(26666,)\n",
            "26666\n",
            "540 neutral\n",
            "540 neutral\n",
            "(26666,)\n",
            "26666\n",
            "541 neutral\n",
            "541 neutral\n",
            "(26666,)\n",
            "26666\n",
            "552 neutral\n",
            "552 neutral\n",
            "(26666,)\n",
            "26666\n",
            "553 neutral\n",
            "553 neutral\n",
            "(26666,)\n",
            "26666\n",
            "556 neutral\n",
            "556 neutral\n",
            "(26666,)\n",
            "26666\n",
            "557 neutral\n",
            "557 neutral\n",
            "(26666,)\n",
            "26666\n",
            "621 neutral\n",
            "621 neutral\n",
            "(26666,)\n",
            "26666\n",
            "622 neutral\n",
            "622 neutral\n",
            "(26666,)\n",
            "26666\n",
            "624 neutral\n",
            "624 neutral\n",
            "(26666,)\n",
            "26666\n",
            "626 neutral\n",
            "626 neutral\n",
            "(26666,)\n",
            "26666\n",
            "628 neutral\n",
            "628 neutral\n",
            "(26666,)\n",
            "26666\n",
            "629 neutral\n",
            "629 neutral\n",
            "(26666,)\n",
            "26666\n",
            "630 neutral\n",
            "630 neutral\n",
            "(26666,)\n",
            "26666\n",
            "631 neutral\n",
            "631 neutral\n",
            "(26666,)\n",
            "26666\n",
            "632 neutral\n",
            "632 neutral\n",
            "(26666,)\n",
            "26666\n",
            "(1803, 12)\n",
            "rand_noise     1700\n",
            "bbc              33\n",
            "high             30\n",
            "low              26\n",
            "low multi         5\n",
            "low complex       5\n",
            "high multi        3\n",
            "low               1\n",
            "Name: Annotation, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}