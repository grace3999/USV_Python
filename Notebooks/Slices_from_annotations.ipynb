{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from skimage import util\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "#from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "#visualizing results\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import yellowbrick as yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slice_from_wav(file_path, slice_len, step_size):\n",
    "    \"\"\"Creates small slices from wav file. Slice_len (use sampling frequency to convert to ms). \n",
    "    Step_size is amount of overlap between each slice.\"\"\"\n",
    "    \n",
    "    #get animal name\n",
    "    \n",
    "    #read in wav file\n",
    "    samp_freq, sig_data = wavfile.read(file_path)\n",
    "    sig_data = sig_data[0:150000000]\n",
    "    print('Sampling frequency: ' + str(samp_freq))\n",
    "    \n",
    "    #determine number of samples and length\n",
    "    n_samples = sig_data.shape[0]\n",
    "    print('Number of samples: ' + str(n_samples))\n",
    "    sig_len = n_samples/samp_freq\n",
    "    print('Length: ' + str(sig_len) + ' sec')\n",
    "    \n",
    "    #create slices \n",
    "    M = slice_len\n",
    "    steps = int(M*step_size)\n",
    "    slices = util.view_as_windows(sig_data, window_shape=(M,), step=steps)\n",
    "    print(f'Audio shape: {sig_data.shape}, Sliced audio shape: {slices.shape}')\n",
    "    \n",
    "    return samp_freq, sig_data, slices, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spec(Sx, times, steps, time_stamp):\n",
    "    \"\"\"Plots a spectrogram from a slice\"\"\"\n",
    "    \n",
    "    f, ax = plt.subplots()\n",
    "    plt.pcolormesh((times*1000) + (time_stamp), freqs_spec / 1000, 10 * np.log10(Sx), cmap = 'cubehelix')\n",
    "    ax.ticklabel_format(useOffset=False)\n",
    "    plt.ylabel('Frequency [kHz]')\n",
    "    plt.xlabel('Time [msec]')\n",
    "    plt.show()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_plot(image_df, time_stamp_list, x, y):\n",
    "    \"\"\"Plots spectrograms from a list of time_stamps\"\"\"\n",
    "    for time_stamp in time_stamp_list[x:y]:\n",
    "        plt.figure(figsize = (2,5))\n",
    "        plt.pcolormesh((times*1000) + (time_stamp), freqs_spec / 1000, 10 * np.log10(image_df[time_stamp]), cmap = 'cubehelix')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(data):\n",
    "    \"\"\"Finds spectral flatness and power sum for each time stamp in a df.\"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    feature_df = pd.DataFrame(index = data.index, columns = ['time_stamp', 'spec_flat', 'power_sum'])\n",
    "    \n",
    "    for time_stamp in data.index:\n",
    "        #spectral flattness\n",
    "        feature_df.loc[time_stamp]['spec_flat'] = (stats.gmean(data.loc[time_stamp])) / (data.loc[time_stamp].mean())\n",
    "        #power sum\n",
    "        feature_df.loc[time_stamp]['power_sum'] = data.loc[time_stamp].sum()\n",
    "        #time stamp\n",
    "        feature_df.loc[time_stamp]['time_stamp'] = time_stamp\n",
    "        \n",
    "    end = time.time()\n",
    "    print(end - start)\n",
    "\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/533.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/534.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/535.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/542.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/543.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/554.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/555.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/559.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/CPA_pair_exp/18.12.07_CPA_pair_3x/noise.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_names = []\n",
    "files = os.listdir(wav_dir_path)\n",
    "for file in files: \n",
    "        path_names.append(wav_dir_path + \"/\" + file)\n",
    "\n",
    "path_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create slices from wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing animal # 533\n",
      "Sampling frequency: 250000\n",
      "Number of samples: 150000000\n",
      "Length: 600.0 sec\n",
      "Audio shape: (150000000,), Sliced audio shape: (26666, 6250)\n",
      "Slices created in 0.25332117080688477  seconds\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "Spectrograms created in 294.86925506591797  seconds\n",
      "Data frame created in 13.448246002197266  seconds\n",
      "Begin processing animal # 534\n",
      "Sampling frequency: 250000\n",
      "Number of samples: 150000000\n",
      "Length: 600.0 sec\n",
      "Audio shape: (150000000,), Sliced audio shape: (26666, 6250)\n",
      "Slices created in 9.161814212799072  seconds\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "Spectrograms created in 1530.364191532135  seconds\n",
      "Data frame created in 16.332616806030273  seconds\n",
      "Begin processing animal # 535\n",
      "Sampling frequency: 250000\n",
      "Number of samples: 150000000\n",
      "Length: 600.0 sec\n",
      "Audio shape: (150000000,), Sliced audio shape: (26666, 6250)\n",
      "Slices created in 7.897553205490112  seconds\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "spec_slices = {}\n",
    "spec_slices_ravel = {}\n",
    "spec_slices_df_dic = {}\n",
    "\n",
    "spec_window = 128\n",
    "NFFT = 512\n",
    "    \n",
    "for path in path_names:\n",
    "    \n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    \n",
    "    print(str('Begin processing animal # ' + name))\n",
    "    \n",
    "    #create slices\n",
    "    start = time.time()\n",
    "    samp_freq, sig_data, slices, steps = create_slice_from_wav(path, 6250, 0.9)\n",
    "    end = time.time()\n",
    "    print(str('Slices created in ' + str(end - start) + '  seconds'))\n",
    "    \n",
    "    #create spectrogram from each slice\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    samp_freq_kHz = samp_freq/1000\n",
    "    spec_slices_int = {}\n",
    "    spec_slices_ravel_int = {}\n",
    "    \n",
    "    for i in range(slices.shape[0]): \n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        #spectrogram\n",
    "        freqs_spec, times, Sx = signal.spectrogram(slices[i,:], fs=samp_freq, nperseg = spec_window, nfft = NFFT)\n",
    "    \n",
    "        time_stamp = i*steps / samp_freq_kHz\n",
    "    \n",
    "        #store as intermediate dic\n",
    "        spec_slices_int[time_stamp] = Sx\n",
    "        spec_slices_ravel_int[time_stamp] = spec_slices_int[time_stamp].ravel().T\n",
    "    \n",
    "    end = time.time()\n",
    "    print(str('Spectrograms created in ' + str(end - start) + '  seconds'))\n",
    "    \n",
    "    #store as dic of dic (animal number is highest dic key)\n",
    "    start = time.time()\n",
    "    spec_slices[name] = spec_slices_int\n",
    "    spec_slices_ravel[name] = spec_slices_ravel_int\n",
    "    \n",
    "    spec_slices_df_int = pd.DataFrame(spec_slices_ravel_int).T\n",
    "    spec_slices_df_dic[name] = spec_slices_df_int\n",
    "    \n",
    "    end = time.time()\n",
    "    print(str('Data frame created in ' + str(end - start) + '  seconds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "533",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-2bbd35f96bc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspec_slices_df_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m533\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 533"
     ]
    }
   ],
   "source": [
    "spec_slices_df_dic[533]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "spec_slices_thresh_df = pd.DataFrame(index = spec_slices_df.index)\n",
    "for time_stamp in spec_slices_df.index:\n",
    "    threshold = np.percentile(spec_slices_df.loc[time_stamp], 70)\n",
    "    spec_slices_thresh_df.loc[time_stamp][spec_slices_df.loc[time_stamp] < threshold] = 0\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "spec_slices_thresh_df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find spectral flatness of each spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = find_features(spec_slices_df)\n",
    "print(features_df.shape)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "spec_flat_df = pd.DataFrame(index = spec_slices_df.index, columns = ['time_stamp', 'spec_flat'])\n",
    "for time_stamp in spec_slices_df.index:\n",
    "    x = spec_slices_df.loc[time_stamp]\n",
    "    spec_flat_df.loc[time_stamp]['spec_flat'] = (stats.gmean(x)) / (x.mean())\n",
    "    spec_flat_df.loc[time_stamp]['time_stamp'] = time_stamp\n",
    "    \n",
    "print(spec_flat_df.shape)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "spec_flat_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot(spec_slices, spec_flat_df.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold on spectral flatness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_flat = np.percentile(spec_flat_df['spec_flat'].values, 25)\n",
    "#print(threshold_flat)\n",
    "spec_flat_df_thresh = spec_flat_df[spec_flat_df['spec_flat'] < .1]\n",
    "print(spec_flat_df_thresh.shape)\n",
    "spec_flat_df_thresh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new df of thresholded slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_stamp_list_power = power_sum_df_thresh.index.values\n",
    "time_stamp_list_flatness = spec_flat_df_thresh.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_slices_df_flat_thresh = spec_slices_df.loc[[time_stamp_list_flatness][0]]\n",
    "print(spec_slices_df_flat_thresh.shape)\n",
    "spec_slices_df_flat_thresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot(spec_slices, time_stamp_list_flatness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find power sum of thresholded slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "power_sum_df = pd.DataFrame(index = spec_slices_df_flat_thresh.index, columns = ['time_stamp', 'power_sum'])\n",
    "for time_stamp in spec_slices_df_flat_thresh.index:\n",
    "    power_sum_df.loc[time_stamp]['power_sum'] = spec_slices_df_flat_thresh.loc[time_stamp].sum()\n",
    "    power_sum_df.loc[time_stamp]['time_stamp'] = time_stamp\n",
    "    \n",
    "print(power_sum_df.shape)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "power_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(power_sum_df['power_sum'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_sum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_sum_df.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold on power sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_power = np.percentile(power_sum_df['power_sum'].values, 20)\n",
    "#print(threshold_power)\n",
    "power_sum_df_thresh = power_sum_df[power_sum_df['power_sum'] > 200000]\n",
    "print(power_sum_df_thresh.shape)\n",
    "power_sum_df_thresh.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def facet_plot(image_df, time_stamp_list_flatness):\n",
    "    plt.figure(figsize = (20,20))\n",
    "    plot_row_num = math.ceil(math.sqrt(len(time_stamp_list_flatness)))\n",
    "    plot_col_num = math.ceil(len(time_stamp_list_flatness) / plot_row_num)\n",
    "    for idx, time_stamp in enumerate(time_stamp_list_flatness):\n",
    "        plt.subplot(plot_row_num, plot_col_num, idx+1)\n",
    "        plt.pcolormesh((times*1000) + (time_stamp), freqs_spec / 1000, 10 * np.log10(image_df[time_stamp]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_plot(spec_slices, time_stamp_list_flatness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=30, whiten=True)\n",
    "X_transformed = pca.fit_transform(np.log(annot_slice_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.singular_values_)\n",
    "plt.title(\"Singular values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first ten components\n",
    "plt.figure(figsize = (10,5))\n",
    "u = pca.components_[:,:].reshape(30,-1,len(times))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    # we are rescaling between 0 and 1 before plotting\n",
    "    plt.imshow(u[i], cmap = 'viridis')\n",
    "    plt.title('Mode '+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_transformed[:,0], X_transformed[:,1], s=40,  marker='o', alpha=.8)\n",
    "#plt.xlim(-100000,100000)\n",
    "#plt.ylim(-100000,100000)\n",
    "plt.title(\"Projection of the data on 2 components + ground truth labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below visualizes the data projected in 2D together with the original spectrograms\n",
    "\n",
    "from matplotlib import offsetbox\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,\n",
    "                                  AnnotationBbox)\n",
    "# Scale and visualize the embedding vectors\n",
    "def plot_embedding(X, X_embedded, title=None):\n",
    "    x_min, x_max = np.min(X_embedded, 0), np.max(X_embedded, 0)\n",
    "    X_embedded = (X_embedded - x_min) / (x_max - x_min)\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    ax = plt.subplot(111)\n",
    "    for i in range(X_embedded.shape[0]):\n",
    "        plt.text(X_embedded[i, 0], X_embedded[i, 1], 'o',\n",
    "                 color=plt.cm.viridis(y[i] / 0.01),\n",
    "                 #color=colors[i],\n",
    "                 #color=int(y[i]),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "\n",
    "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
    "        # only print thumbnails with matplotlib > 1.0\n",
    "        shown_images = np.array([[1., 1.]])  # just something big\n",
    "        for i in range(X_embedded.shape[0]):\n",
    "            dist = np.sum((X_embedded[i,:] - shown_images) ** 2, 1)\n",
    "            if np.min(dist) < 4e-3:\n",
    "                # don't show points that are too close\n",
    "                continue\n",
    "            shown_images = np.r_[shown_images, [X_embedded[i,:]]]\n",
    "            imagebox = offsetbox.AnnotationBbox(\n",
    "                offsetbox.OffsetImage(np.log(X[i,:].reshape(spec_dim)),zoom = 0.3, cmap='plasma'),\n",
    "                X_embedded[i,:])\n",
    "            ax.add_artist(imagebox)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    if title is not None:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embedding(np.array(annot_slice_df), X_transformed[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center and scale the data\n",
    "scaler = StandardScaler()\n",
    "slices_scaled = scaler.fit_transform(spec_slices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_range = range(2,20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    km_ss = KMeans(n_clusters=k, random_state=1)\n",
    "    km_ss.fit(slices_scaled)\n",
    "    scores.append(silhouette_score(slices_scaled, km_ss.labels_))\n",
    "\n",
    "# plot the results\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Coefficient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km2 = KMeans(n_clusters=3,random_state=1234)\n",
    "km2.fit(slices_scaled)\n",
    "score = silhouette_score(slices_scaled, km_ss.labels_)\n",
    "#summary_ave['kmeans_2_scaled'] = [ \"cluster_\" + str(label) for label in km2.labels_ ]\n",
    "#summary_ave.groupby('kmeans_2_scaled').mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create df of annotated USVs from RavenLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_path = \"C:/Users/Schindler/Documents/Schindler_Lab/Data/Analysis/Excel files/USV/USV_annot.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(annot_path)\n",
    "annot_data = pd.DataFrame(data = data)\n",
    "annot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_data.groupby(['Animal', 'Session', 'Annotation']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine closest time stamp of each annotation and add as column to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_data['Begin Time (s)_1000'] = annot_data['Begin Time (s)']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_time_stamps = []\n",
    "values = annot_data['Begin Time (s)_1000'].values\n",
    "for value in values:\n",
    "    time_stamp_num = int(value / 22.5)\n",
    "    time_stamp_index = time_stamp_num*22.5\n",
    "    annot_time_stamps.append(time_stamp_index)\n",
    "\n",
    "annot_data['time_stamp'] = annot_time_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_535 = annot_data[(annot_data['Animal'] == 535)]\n",
    "annot_535.reset_index(inplace = True)\n",
    "annot_535.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_535_low_multi = annot_535[annot_535['Annotation'].str.contains('low multi', regex=False)]\n",
    "print(annot_535_low_multi.shape)\n",
    "annot_535_low_multi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_535_low_multi_slices = spec_slices_df.loc[annot_535_low_multi['time_stamp']]\n",
    "print(annot_535_low_multi_slices.shape)\n",
    "annot_535_low_multi_slices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_features_df_535_low_multi_slices = find_features(annot_535_low_multi_slices)\n",
    "print(annot_features_df_535_low_multi_slices.shape)\n",
    "annot_features_df_535_low_multi_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annot_features_df_535_low_multi_slices['spec_flat'].max())\n",
    "print(annot_features_df_535_low_multi_slices['spec_flat'].min())\n",
    "print(annot_features_df_535_low_multi_slices['spec_flat'].mean())\n",
    "print(annot_features_df_535_low_multi_slices['power_sum'].max())\n",
    "print(annot_features_df_535_low_multi_slices['power_sum'].min())\n",
    "print(annot_features_df_535_low_multi_slices['power_sum'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp_list = annot_slice_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_plot(spec_slices, time_stamp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(annot_features_df_535_low_multi_slices['power_sum'].values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
