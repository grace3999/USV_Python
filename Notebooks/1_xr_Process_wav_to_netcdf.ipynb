{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "from skimage import util\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slice_from_wav(file_path, slice_len, step_size):\n",
    "    \"\"\"Creates small slices from wav file. Slice_len (use sampling frequency to convert to ms). \n",
    "    Step_size is amount of overlap between each slice.\"\"\"\n",
    "    \n",
    "    #read in wav file\n",
    "    samp_freq, sig_data = wavfile.read(file_path)\n",
    "    sig_data = sig_data[0:150000000]\n",
    "    print('Sampling frequency: ' + str(samp_freq))\n",
    "    \n",
    "    #determine number of samples and length\n",
    "    n_samples = sig_data.shape[0]\n",
    "    print('Number of samples: ' + str(n_samples))\n",
    "    sig_len = n_samples/samp_freq\n",
    "    print('Length: ' + str(sig_len) + ' sec')\n",
    "    \n",
    "    #create slices \n",
    "    M = slice_len\n",
    "    steps = int(M*step_size)\n",
    "    slices = util.view_as_windows(sig_data, window_shape=(M,), step=steps)\n",
    "    print(f'Audio shape: {sig_data.shape}, Sliced audio shape: {slices.shape}')\n",
    "    \n",
    "    return samp_freq, sig_data, slices, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spec_from_slice_array(slices, spec_window=128, NFFT=512, samp_freq=250000, steps=5625):\n",
    "    \"\"\"Creates fft spectrogram from slice. spec_window is length of each segment (nperseg).\n",
    "    NFFT is length of the FFT used (nfft). samp_freq is sampling frequency (in Hz) of slice (fs).\n",
    "    steps is step size between slices\"\"\"\n",
    "    #create spectrogram from each slice\n",
    "    \n",
    "    spec_slices = {}\n",
    "    samp_freq_kHz = samp_freq/1000\n",
    "\n",
    "    for i in range(slices.shape[0]): \n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        #spectrogram\n",
    "        freqs_spec, times, Sx = signal.spectrogram(slices[i,:], fs=samp_freq, nperseg = spec_window, nfft = NFFT)\n",
    "    \n",
    "        time_stamp = i*steps / samp_freq_kHz\n",
    "    \n",
    "        #store as dic\n",
    "        spec_slices[time_stamp] = Sx\n",
    "\n",
    "    return spec_slices, freqs_spec, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xarray_dataset_from_dic(dic, freqs_spec, times):\n",
    "    \"\"\"Creates an xarray.Dataset object from a dictionary input.\"\"\"\n",
    "    \n",
    "    slices_combined = {}\n",
    "    \n",
    "    for key, fft_slice in dic.items():\n",
    "        slices_combined[key] = xr.DataArray(fft_slice, dims = ('freq', 'times'), coords = {'freq': freqs_spec, 'times': times})\n",
    "    slices_Dataset = xr.Dataset(slices_combined).to_array(dim = 'slices')\n",
    "    \n",
    "    return slices_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find path names for each wav file corresponding to annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir_path = 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/527.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/529.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/540.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/541.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/552.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/553.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/556.wav',\n",
       " 'C:/Users/Schindler/Documents/Schindler_Lab/Data/USVs/18.12.05_neutral_pair_3x/557.wav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_names = []\n",
    "files = os.listdir(wav_dir_path)\n",
    "for file in files: \n",
    "        path_names.append(wav_dir_path + \"/\" + file)\n",
    "\n",
    "path_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing animal # 557\n",
      "Sampling frequency: 250000\n",
      "Number of samples: 150000000\n",
      "Length: 600.0 sec\n",
      "Audio shape: (150000000,), Sliced audio shape: (26666, 6250)\n",
      "Slices created in 1.8218762874603271  seconds\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "Spectrograms created in 109.53799653053284  seconds\n",
      "xarray created in 39.46721935272217  seconds\n",
      "xarray saved in 138.1981360912323  seconds\n"
     ]
    }
   ],
   "source": [
    "#select animal to process (need to process individually due to memory contraints)\n",
    "path = path_names[7]\n",
    "name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "\n",
    "#process wav file of animal corresponding to annotations\n",
    "print(str('Begin processing animal # ' + name))\n",
    "\n",
    "#create slices\n",
    "start = time.time()\n",
    "samp_freq, sig_data, slices, steps = create_slice_from_wav(path, 6250, 0.9)\n",
    "end = time.time()\n",
    "print(str('Slices created in ' + str(end - start) + '  seconds'))\n",
    "\n",
    "#create spectrograms\n",
    "start = time.time()\n",
    "spec_slices, freqs_spec, times = create_spec_from_slice_array(slices, spec_window=128, NFFT=512, samp_freq=250000, steps=5625)\n",
    "end = time.time()\n",
    "print(str('Spectrograms created in ' + str(end - start) + '  seconds'))\n",
    "\n",
    "#create xarray Dataset\n",
    "start = time.time()\n",
    "slices_Dataset = create_xarray_dataset_from_dic(spec_slices, freqs_spec, times)\n",
    "end = time.time()\n",
    "print(str('xarray created in ' + str(end - start) + '  seconds'))\n",
    "\n",
    "#save\n",
    "start = time.time()\n",
    "slices_Dataset.to_netcdf(name + '_xr_Dataset.nc')\n",
    "end = time.time()\n",
    "print(str('xarray saved in ' + str(end - start) + '  seconds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
