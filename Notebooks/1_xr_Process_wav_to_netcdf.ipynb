{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "\n",
    "from skimage import util\n",
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "import xarray as xr\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_slice_from_wav(file_path, file_len, slice_len, step_size):\n",
    "    \"\"\"Creates small slices from wav file. file_length is desired length of file in minutes.\n",
    "    slice_len is desired legth of each slice in ms. \n",
    "    step_size is how big of step to take between steps (larger size is less overlap).\"\"\"\n",
    "    \n",
    "    #read in wav file\n",
    "    samp_freq, sig_data = wavfile.read(file_path)\n",
    "    print('Sampling frequency: ' + str(samp_freq))\n",
    "    \n",
    "    #convert file_length from min to sample numbers\n",
    "    file_length_num = file_len*samp_freq*60\n",
    "    \n",
    "    #convert slice_len from ms to sample numbers\n",
    "    slice_sample_num = slice_len*samp_freq/1000\n",
    "    \n",
    "    #use only slices within file_length\n",
    "    sig_data = sig_data[0:file_length_num]\n",
    "    \n",
    "    #determine number of samples and length\n",
    "    n_samples = sig_data.shape[0]\n",
    "    print('Number of samples: ' + str(n_samples))\n",
    "    sig_len = n_samples/samp_freq\n",
    "    print('Length: ' + str(sig_len) + ' sec')\n",
    "    \n",
    "    #create slices \n",
    "    steps = int(slice_sample_num*step_size)\n",
    "    slices = util.view_as_windows(sig_data, window_shape=(slice_sample_num,), step=steps)\n",
    "    print(f'Audio shape: {sig_data.shape}, Sliced audio shape: {slices.shape}')\n",
    "    \n",
    "    return samp_freq, sig_data, slices, steps, sig_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spec_from_slice_array(slices, steps, spec_window, NFFT, samp_freq):\n",
    "    \"\"\"Creates fft spectrogram from slice. spec_window is length of each segment (nperseg).\n",
    "    NFFT is length of the FFT used (nfft). samp_freq is sampling frequency (in Hz) of slice (fs).\n",
    "    steps is step size between slices\"\"\"\n",
    "    \n",
    "    spec_slices = {}\n",
    "    samp_freq_kHz = samp_freq/1000\n",
    "\n",
    "    for i in range(slices.shape[0]): \n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        #spectrogram\n",
    "        freqs_spec, times, Sx = signal.spectrogram(slices[i,:], fs=samp_freq, nperseg = spec_window, nfft = NFFT)\n",
    "    \n",
    "        time_stamp = (i*steps) / samp_freq_kHz\n",
    "    \n",
    "        #store as dic\n",
    "        spec_slices[time_stamp] = Sx\n",
    "\n",
    "    return spec_slices, freqs_spec, times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xarray_dataset_from_dic(dic, freqs_spec, times):\n",
    "    \"\"\"Creates an xarray.Dataset object from a dictionary input.\"\"\"\n",
    "    \n",
    "    slices_combined = {}\n",
    "    \n",
    "    for key, fft_slice in dic.items():\n",
    "        slices_combined[key] = xr.DataArray(fft_slice, dims = ('freq', 'times'), coords = {'freq': freqs_spec, 'times': times})\n",
    "    slices_Dataset = xr.Dataset(slices_combined).to_array(dim = 'slices')\n",
    "    \n",
    "    return slices_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing function\n",
    "def get_remainders(slices_Dataset, slices, step_size, samp_freq, sig_len):\n",
    "    slice_remainder = np.ceil((sig_len - (slices.shape[0] * slices.shape[1] * step_size / samp_freq))*1000)\n",
    "    netcdf_remainder = (sig_len * 1000) - slices_Dataset.slices.values[-1] - 22.5\n",
    "    \n",
    "    return slice_remainder, netcdf_remainder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find path names for each wav file corresponding to annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir_path = 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Data/Wav_files/18.12.07_CPA_pair_3x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_names = []\n",
    "files = os.listdir(wav_dir_path)\n",
    "for file in files: \n",
    "        path_names.append(wav_dir_path + \"/\" + file)\n",
    "\n",
    "len(path_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin processing animal # 533\n",
      "Sampling frequency: 250000\n",
      "Number of samples: 150000000\n",
      "Length: 600.0 sec\n",
      "Audio shape: (150000000,), Sliced audio shape: (26666, 6250)\n",
      "Slices created in 0.2583029270172119  seconds\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "Spectrograms created in 77.87618231773376  seconds\n",
      "xarray created in 91.77794933319092  seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile)\u001b[0m\n\u001b[0;32m    746\u001b[0m         dump_to_store(dataset, store, writer, encoding=encoding,\n\u001b[1;32m--> 747\u001b[1;33m                       unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m    748\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\api.py\u001b[0m in \u001b[0;36mdump_to_store\u001b[1;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[0;32m    789\u001b[0m     store.store(variables, attrs, check_encoding, writer,\n\u001b[1;32m--> 790\u001b[1;33m                 unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\common.py\u001b[0m in \u001b[0;36mstore\u001b[1;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[0;32m    265\u001b[0m         self.set_variables(variables, check_encoding_set, writer,\n\u001b[1;32m--> 266\u001b[1;33m                            unlimited_dims=unlimited_dims)\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\common.py\u001b[0m in \u001b[0;36mset_variables\u001b[1;34m(self, variables, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\common.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, source, target)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\netCDF4_.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-12feb8b24a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m#save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mslices_Dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_xr_Dataset.nc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'xarray saved in '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'  seconds'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\core\\dataarray.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1750\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1752\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_netcdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\core\\dataset.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[1;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute)\u001b[0m\n\u001b[0;32m   1230\u001b[0m                          \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m                          \u001b[0munlimited_dims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munlimited_dims\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m                          compute=compute)\n\u001b[0m\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m     def to_zarr(self, store=None, mode='w-', synchronizer=None, group=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\xarray\\backends\\api.py\u001b[0m in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile)\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmultifile\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompute\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m             \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_len=10\n",
    "slice_len=25\n",
    "step_size=0.9\n",
    "\n",
    "spec_window=128\n",
    "NFFT=512\n",
    "\n",
    "for path in path_names:\n",
    "    \n",
    "    #get animal name from file\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "\n",
    "    #process wav file of animal corresponding to annotations\n",
    "    print(str('Begin processing animal # ' + name))\n",
    "\n",
    "    #create slices\n",
    "    start = time.time()\n",
    "    samp_freq, sig_data, slices, steps, sig_len = create_slice_from_wav(path, file_len, slice_len, step_size)\n",
    "    end = time.time()\n",
    "    print(str('Slices created in ' + str(end - start) + '  seconds'))\n",
    "\n",
    "    #create spectrograms\n",
    "    start = time.time()\n",
    "    spec_slices, freqs_spec, times = create_spec_from_slice_array(slices, steps, spec_window, NFFT, samp_freq)\n",
    "    end = time.time()\n",
    "    print(str('Spectrograms created in ' + str(end - start) + '  seconds'))\n",
    "\n",
    "    #create xarray Dataset\n",
    "    start = time.time()\n",
    "    slices_Dataset = create_xarray_dataset_from_dic(spec_slices, freqs_spec, times)\n",
    "    end = time.time()\n",
    "    print(str('xarray created in ' + str(end - start) + '  seconds'))\n",
    "\n",
    "    #confirm timestamps are correct\n",
    "    slice_remainder, netcdf_remainder = get_remainders(slices_Dataset, slices, step_size, samp_freq, sig_len)\n",
    "    if slice_remainder != netcdf_remainder:\n",
    "        raise Exception('Mismatch between slice and timestamp remainders')\n",
    "    else:\n",
    "        #save    \n",
    "        start = time.time()\n",
    "        slices_Dataset.to_netcdf(name + '_xr_Dataset.nc')\n",
    "        end = time.time()\n",
    "        print(str('xarray saved in ' + str(end - start) + '  seconds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
