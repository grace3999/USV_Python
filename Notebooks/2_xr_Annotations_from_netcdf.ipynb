{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Schindler\\AppData\\Local\\conda\\conda\\envs\\USV_python\\lib\\site-packages\\distributed\\utils.py:134: RuntimeWarning: Couldn't detect a suitable IP address for reaching '8.8.8.8', defaulting to '127.0.0.1': [WinError 10065] A socket operation was attempted to an unreachable host\n",
      "  % (host, default, e), RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annot_dataset(path, annot_data, size_random):\n",
    "    \"\"\"takes in path of netcdf file (created using notebook 1) and corresponding annotations (created using notebook 0)\n",
    "    and creates a new data set of only slices correspondingn to annotations (and random noise if set to True)\"\"\"\n",
    "    \n",
    "    #get animal name from path\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    print(name)\n",
    "    \n",
    "    #open xarray Dataset\n",
    "    data = xr.open_dataset(path)\n",
    "    print(data['slices'].shape)\n",
    "    \n",
    "    #get time_stamps of animal's annotations, select slices and save\n",
    "    yes = annot_data[annot_data['animal_number'] ==  int(name)]['time_stamp'].sort_values().values\n",
    "    data_yes = data.sel(slices = yes)\n",
    "    \n",
    "    #get slice indexs (e.g. time_stamps) that are not annotations, select slices and save\n",
    "    slice_indexes = data['slices'].values\n",
    "    no = np.setdiff1d(slice_indexes,yes)\n",
    "    print(yes.shape[0] + no.shape[0])\n",
    "    no_short = np.random.choice(no, size_random, replace=False)\n",
    "    data_no = data.sel(slices = no_short)\n",
    "    \n",
    "    return data_yes, data_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_features(Dataset):\n",
    "    \"\"\"takes in netcdf dataset and computes 8 features\"\"\"\n",
    "    \n",
    "    spec_power = []\n",
    "    spec_purs = []\n",
    "    spec_centroid = []\n",
    "    spec_spread = []\n",
    "    spec_skewness = []\n",
    "    spec_kurtosis = []\n",
    "    spec_slope = []\n",
    "    spec_roll_off = []\n",
    "    \n",
    "    freq_array = Dataset['freq'].values\n",
    "    \n",
    "    #compute power sum using groupby\n",
    "    spec_power = Dataset.groupby('slices').sum(xr.ALL_DIMS)['__xarray_dataarray_variable__'].values\n",
    "    \n",
    "    #compute other features for each slice individually\n",
    "    for value in Dataset['slices'].values:\n",
    "        \n",
    "        spec_pur = stats.gmean(Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values, axis = None) / Dataset.sel(slices = value)['__xarray_dataarray_variable__'].values.mean()\n",
    "        \n",
    "        mag_array = Dataset['__xarray_dataarray_variable__'].sel(slices=value).max(dim = 'times').values\n",
    "        mag_probs = mag_array/sum(mag_array)\n",
    "        freq_mag = freq_array*mag_probs\n",
    "        \n",
    "        spec_cent = sum(freq_mag)\n",
    "        spec_spr = np.var(freq_mag)\n",
    "        spec_skew = stats.skew(freq_mag)\n",
    "        spec_kurt = stats.kurtosis(freq_mag)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(freq_array, freq_mag)\n",
    "        spec_ro = .95*sum(freq_mag)\n",
    "        \n",
    "        spec_purs.append(spec_pur)\n",
    "        spec_centroid.append(spec_cent)\n",
    "        spec_spread.append(spec_spr)\n",
    "        spec_skewness.append(spec_skew)\n",
    "        spec_kurtosis.append(spec_kurt)\n",
    "        spec_slope.append(slope)\n",
    "        spec_roll_off.append(spec_ro)\n",
    "        \n",
    "    return spec_power, spec_purs, spec_centroid, spec_spread, spec_skewness, spec_kurtosis, spec_slope, spec_roll_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotation_slice_features(path, annot_data, size_random = 50):\n",
    "    \"\"\"takes in path of netcdf file (created using notebook 1), corresponding annotations (created using notebook 0),\n",
    "    and size desired for random slicecs from each file.\n",
    "    uses create_annot_dataset and compute_spectral_features functions to create a new data set of computed features\n",
    "    for only slices correspondingn to annotations and random noise\"\"\"\n",
    "    \n",
    "    \n",
    "    #get animal name from path\n",
    "    name = re.search(\"\\d\\d\\d\", path).group(0)\n",
    "    print(name)\n",
    "    \n",
    "    #create datasets of slices of known annotations and a random selection of noise\n",
    "    data_yes, data_no = create_annot_dataset(path, annot_data, size_random)\n",
    "    \n",
    "    #compute spectral features\n",
    "    yes_spec_power, yes_spec_purs, yes_spec_centroid, yes_spec_spread, yes_spec_skewness, yes_spec_kurtosis, yes_spec_slope, yes_spec_roll_off = compute_spectral_features(data_yes)\n",
    "    no_spec_power, no_spec_purs, no_spec_centroid, no_spec_spread, no_spec_skewness, no_spec_kurtosis, no_spec_slope, no_spec_roll_off = compute_spectral_features(data_no)\n",
    "\n",
    "    #add computed features to exisiting dataframe of known annotations\n",
    "    annot_yes = annot_data[annot_data['animal_number'] == int(name)].sort_values(by=['time_stamp'])\n",
    "    annot_yes['power_sum'] = yes_spec_power\n",
    "    annot_yes['spec_pur'] = yes_spec_purs\n",
    "    annot_yes['spec_cent'] = yes_spec_centroid\n",
    "    annot_yes['spec_spread'] = yes_spec_spread\n",
    "    annot_yes['spec_skew'] = yes_spec_skewness\n",
    "    annot_yes['spec_kurt'] = yes_spec_kurtosis\n",
    "    annot_yes['spec_slope'] = yes_spec_slope\n",
    "    annot_yes['spec_roll'] = yes_spec_roll_off\n",
    "    \n",
    "    #create and fill dataframe for randomly selected noise slices\n",
    "    annot_no = pd.DataFrame(columns = ['animal_number', 'session', 'time_stamp', 'Annotation'], index = np.arange(0,size_random))\n",
    "    annot_no['animal_number'] = name\n",
    "    annot_no['session'] = annot_data[annot_data['animal_number'] == int(name)]['session'].iloc[0]\n",
    "    annot_no['Annotation'] = 'rand_noise'\n",
    "    annot_no['time_stamp'] = data_no['slices'].values\n",
    "    annot_no['power_sum'] = no_spec_power\n",
    "    annot_no['spec_pur'] = no_spec_purs\n",
    "    annot_no['spec_cent'] = no_spec_centroid\n",
    "    annot_no['spec_spread'] = no_spec_spread\n",
    "    annot_no['spec_skew'] = no_spec_skewness\n",
    "    annot_no['spec_kurt'] = no_spec_kurtosis\n",
    "    annot_no['spec_slope'] = no_spec_slope\n",
    "    annot_no['spec_roll'] = no_spec_roll_off\n",
    "    \n",
    "    return annot_yes, annot_no "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data frame of annotation info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_path_CPA = \"C:/Users/Schindler/Documents/ProgrammingFun/USV_python/annot_df_3x_CPA_pair_tables.csv\"\n",
    "annot_path_novel = \"C:/Users/Schindler/Documents/ProgrammingFun/USV_python/annot_df_3x_novel_pair_tables.csv\"\n",
    "annot_paths = [annot_path_CPA, annot_path_novel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 5)\n",
      "low slug      48\n",
      "low multi     20\n",
      "bbc           15\n",
      "high slug      6\n",
      "high multi     1\n",
      "Name: Annotation, dtype: int64\n",
      "(69, 5)\n",
      "bbc           30\n",
      "high slug     21\n",
      "low slug      12\n",
      "low multi      3\n",
      "high multi     3\n",
      "Name: Annotation, dtype: int64\n",
      "(159, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>animal_number</th>\n",
       "      <th>session</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>Annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>46305.0</td>\n",
       "      <td>low slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>533</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>149692.5</td>\n",
       "      <td>low slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>533</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>243157.5</td>\n",
       "      <td>low slug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>533</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>295560.0</td>\n",
       "      <td>low multi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>533</td>\n",
       "      <td>CPApair</td>\n",
       "      <td>376560.0</td>\n",
       "      <td>low slug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  animal_number  session  time_stamp Annotation\n",
       "0             0            533  CPApair     46305.0   low slug\n",
       "2             2            533  CPApair    149692.5   low slug\n",
       "3             3            533  CPApair    243157.5   low slug\n",
       "4             4            533  CPApair    295560.0  low multi\n",
       "141         141            533  CPApair    376560.0   low slug"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_data = pd.DataFrame()\n",
    "\n",
    "for path in annot_paths:\n",
    "    annot = pd.read_csv(path)\n",
    "    annot = pd.DataFrame(data = annot)\n",
    "    annot = annot[annot['Annotation'] != 'radar']\n",
    "    print(annot.shape)\n",
    "    print(annot.Annotation.value_counts())\n",
    "    \n",
    "    annot_data = annot_data.append(annot)\n",
    "\n",
    "print(annot_data.shape)\n",
    "annot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find path names for each netcdf file corresponding to wav file that has annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf_path = 'C:/Users/Schindler/Documents/ProgrammingFun/USV_python/Datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_names = []\n",
    "files = os.listdir(netcdf_path)\n",
    "for file in files: \n",
    "        path_names.append(netcdf_path + \"/\" + file)\n",
    "\n",
    "len(path_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527\n",
      "527\n",
      "(26666,)\n",
      "26666\n",
      "529\n",
      "529\n",
      "(26666,)\n",
      "26666\n",
      "533\n",
      "533\n",
      "(26666,)\n",
      "26666\n",
      "534\n",
      "534\n",
      "(26666,)\n",
      "26666\n",
      "535\n",
      "535\n",
      "(26666,)\n",
      "26666\n",
      "540\n",
      "540\n",
      "(26666,)\n",
      "26666\n",
      "541\n",
      "541\n",
      "(26666,)\n",
      "26666\n",
      "542\n",
      "542\n",
      "(26666,)\n",
      "26666\n",
      "543\n",
      "543\n",
      "(26666,)\n",
      "26666\n",
      "552\n",
      "552\n",
      "(26666,)\n",
      "26666\n",
      "553\n",
      "553\n",
      "(26666,)\n",
      "26666\n",
      "554\n",
      "554\n",
      "(26666,)\n",
      "26666\n",
      "555\n",
      "555\n",
      "(26666,)\n",
      "26666\n",
      "556\n",
      "556\n",
      "(26666,)\n",
      "26666\n",
      "557\n",
      "557\n",
      "(26666,)\n",
      "26666\n",
      "559\n",
      "559\n",
      "(26666,)\n",
      "26666\n",
      "(959, 12)\n",
      "rand_noise    800\n",
      "low slug       60\n",
      "bbc            45\n",
      "high slug      27\n",
      "low multi      23\n",
      "high multi      4\n",
      "Name: Annotation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "annot_features_yes = pd.DataFrame()\n",
    "annot_features_no = pd.DataFrame()\n",
    "\n",
    "for path in path_names:\n",
    "    \n",
    "    annot_yes, annot_no = create_annotation_slice_features(path, annot_data, size_random = 50)\n",
    "    \n",
    "    annot_features_yes = annot_features_yes.append(annot_yes, ignore_index=True)\n",
    "    annot_features_no = annot_features_no.append(annot_no, ignore_index=True)\n",
    "\n",
    "#create and save combined dataframe of yes and no\n",
    "annot_features_yes.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "annot_features_full = pd.concat([annot_features_yes, annot_features_no])\n",
    "print(annot_features_full.shape)\n",
    "print(annot_features_full.Annotation.value_counts())\n",
    "\n",
    "annot_features_full.to_csv('annot_features_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
