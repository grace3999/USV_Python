{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_xr_Annotations_from_netcdf_PSD.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grace3999/USV_Python/blob/colab/Notebooks/2_xr_Annotations_from_netcdf_PSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "deqrCXk9rI0V",
        "colab_type": "code",
        "outputId": "9c2d9a2d-c3ca-4eb5-a24c-e5253f632b30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#mount google drive containings required files: 1) csv of annotation features, 2) netcdf files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FQy4DI2h2Xkx",
        "colab_type": "code",
        "outputId": "7a02baad-c098-4a0b-b746-c14654db96f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install netcdf4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.6/dist-packages (1.4.3.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.0.3.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from netcdf4) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yt2j-aLYrGyp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from scipy import stats\n",
        "import xarray as xr\n",
        "\n",
        "#visualizing results\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "\n",
        "import warnings; warnings.simplefilter('ignore')\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AWxUzYD-IgJx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#may need to be updated based on file naming scheme\n",
        "def get_file_info(path, order):\n",
        "    \"\"\"takes in a file path for annotation selections table and finds the animal_number and session and saves each accordingly. \n",
        "    each file should be named with animal number and exp (e.g. 100_CPA.Table.1.selections)\"\"\"\n",
        "    \n",
        "    if order == 'animal':\n",
        "      animal_number, session = re.split('_|-', path.split('/')[-1].split('.')[0])[0:2]\n",
        "    else:\n",
        "      session, animal_number = re.split('_|-', path.split('/')[-1].split('.')[0])[0:2] \n",
        "    \n",
        "    print(animal_number, session)\n",
        "    \n",
        "    return animal_number, session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ci9n5RHOrGzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#need to be updated with animal naming scheme (e.g. int(animal_number) vs animal_number)\n",
        "def create_annot_dataset(path, animal_number, session, annot_data, size_random):\n",
        "    \"\"\"takes in path of netcdf file (created using notebook 1) and corresponding annotations (created using notebook 0)\n",
        "    and creates a new data set of only slices correspondingn to annotations (and random noise if set to True)\"\"\"\n",
        "    \n",
        "    #open xarray Dataset\n",
        "    data = xr.open_dataset(path)\n",
        "    print(data['slices'].shape)\n",
        "    \n",
        "    #get time_stamps of animal's annotations, select slices and save\n",
        "    yes = annot_data[(annot_data['animal_number'] ==  animal_number) & (annot_data['session'] ==  session)]['time_stamp'].sort_values().values\n",
        "    data_yes = data.sel(slices = yes)\n",
        "    \n",
        "    #get slice indexs (e.g. time_stamps) that are not annotations, select slices and save\n",
        "    slice_indexes = data['slices'].values\n",
        "    no = np.setdiff1d(slice_indexes,yes)\n",
        "    print(yes.shape[0] + no.shape[0])\n",
        "    no_short = np.random.choice(no, size_random, replace=False)\n",
        "    data_no = data.sel(slices = no_short)\n",
        "    \n",
        "    return data_yes, data_no"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bW_-JbWsf2XN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_psd(Dataset):\n",
        "  \"\"\"takes in netcdf dataset and computes psd, saves as df\"\"\"\n",
        "  \n",
        "  psd_df = pd.DataFrame(data = Dataset.groupby('slices').sum(dim='times')['__xarray_dataarray_variable__'].values, index = Dataset['slices'].values, columns = Dataset['freq'].values/1000)\n",
        "  \n",
        "  return psd_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bTS2dhKah1rH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_annotation_slice_psds(path, order, annot_data, size_random = 15):\n",
        "    \"\"\"takes in path of netcdf file (created using notebook 1), corresponding annotations (created using notebook 0),\n",
        "    and size desired for random slicecs from each file.\n",
        "    uses create_annot_dataset and compute_psd functions to create a new data set of computed features\n",
        "    for only slices correspondingn to annotations and random noise\"\"\"\n",
        "\n",
        "    animal_number, session = get_file_info(path, order)\n",
        "    print(animal_number, session)\n",
        "    \n",
        "    #create datasets of slices of known annotations and a random selection of noise\n",
        "    data_yes, data_no = create_annot_dataset(path, animal_number, session, annot_data, size_random)\n",
        "    \n",
        "    #compute psd\n",
        "    yes_psd = compute_psd(data_yes)\n",
        "    no_psd = compute_psd(data_no)\n",
        "\n",
        "    #add psd to exisiting dataframe of known annotations\n",
        "    annot_yes_psd = annot_data[(annot_data['animal_number'] ==  animal_number) & (annot_data['session'] ==  session)].sort_values(by=['time_stamp'])\n",
        "    annot_yes_psd = pd.merge(annot_yes_psd, yes_psd, left_on=annot_yes_psd['time_stamp'], right_on=yes_psd.index.values)\n",
        "    \n",
        "    #create and fill dataframe for randomly selected noise slices\n",
        "    annot_no_psd = pd.DataFrame(columns = ['animal_number', 'session', 'time_stamp', 'Annotation'], index = np.arange(0,size_random))\n",
        "    annot_no_psd['animal_number'] = animal_number\n",
        "    annot_no_psd['session'] = session\n",
        "    annot_no_psd['Annotation'] = 'rand_noise'\n",
        "    annot_no_psd['time_stamp'] = data_no['slices'].values\n",
        "    annot_no_psd = pd.merge(annot_no_psd, no_psd, left_on=annot_no_psd['time_stamp'], right_on=no_psd.index.values)\n",
        "    \n",
        "    return annot_yes_psd, annot_no_psd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dlRo_PFFrGzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create data frame of annotation info"
      ]
    },
    {
      "metadata": {
        "id": "6DAhrRKCrGz2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Find path names for each netcdf file corresponding to wav file that has annotated data"
      ]
    },
    {
      "metadata": {
        "id": "BWxUEmy_rGzr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "annot_path_cage = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_homecage.csv'\n",
        "annot_path_CPApost = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_CPA.csv'\n",
        "annot_path_pain = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/annotation_data_frames/annot_df_pain.csv'\n",
        "\n",
        "annot_paths = [annot_path_CPApost, annot_path_cage, annot_path_pain]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ks2ASEkirGzx",
        "colab_type": "code",
        "outputId": "c71d3134-39c0-4984-8d4e-5f1653c11f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        }
      },
      "cell_type": "code",
      "source": [
        "annot_data = pd.DataFrame()\n",
        "\n",
        "for path in annot_paths:\n",
        "    annot = pd.read_csv(path)\n",
        "    annot = pd.DataFrame(data = annot)\n",
        "    if 'radar' in annot['Annotation'].values:\n",
        "      annot = annot[annot['Annotation'] != 'radar']\n",
        "    if True in pd.isna(annot['Annotation']).values:\n",
        "      annot['Annotation'] = ['BBC'] * annot['Annotation'].shape[0]\n",
        "    \n",
        "    print(annot.shape)\n",
        "    print(annot.Annotation.value_counts())\n",
        "    \n",
        "    annot_data = annot_data.append(annot)\n",
        "\n",
        "print(annot_data.shape)\n",
        "annot_data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(90, 6)\n",
            "low slug      48\n",
            "low multi     20\n",
            "bbc           15\n",
            "high slug      6\n",
            "high multi     1\n",
            "Name: Annotation, dtype: int64\n",
            "(69, 6)\n",
            "bbc           30\n",
            "high slug     21\n",
            "low slug      12\n",
            "low multi      3\n",
            "high multi     3\n",
            "Name: Annotation, dtype: int64\n",
            "(178, 6)\n",
            "BBC    178\n",
            "Name: Annotation, dtype: int64\n",
            "(337, 6)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>animal_number</th>\n",
              "      <th>session</th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>Annotation</th>\n",
              "      <th>High Freq (Hz)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>46305.0</td>\n",
              "      <td>low slug</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>149692.5</td>\n",
              "      <td>low slug</td>\n",
              "      <td>16074.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>243157.5</td>\n",
              "      <td>low slug</td>\n",
              "      <td>16500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>295560.0</td>\n",
              "      <td>low multi</td>\n",
              "      <td>27489.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>141</td>\n",
              "      <td>533</td>\n",
              "      <td>CPApair</td>\n",
              "      <td>376560.0</td>\n",
              "      <td>low slug</td>\n",
              "      <td>9940.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0 animal_number  session  time_stamp Annotation  High Freq (Hz)\n",
              "0             0           533  CPApair     46305.0   low slug         16500.0\n",
              "2             2           533  CPApair    149692.5   low slug         16074.5\n",
              "3             3           533  CPApair    243157.5   low slug         16500.0\n",
              "4             4           533  CPApair    295560.0  low multi         27489.6\n",
              "141         141           533  CPApair    376560.0   low slug          9940.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "RqrhyDzlrGz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "netcdf_path_fear = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Fear'\n",
        "\n",
        "netcdf_path_pain = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jgYEAG9BrGz7",
        "colab_type": "code",
        "outputId": "0f221b79-24e5-4b9a-ef79-4f86ceefff1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "path = netcdf_path_pain\n",
        "\n",
        "path_names = []\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "  path_names.append(path + \"/\" + file)\n",
        "\n",
        "print(len(path_names))\n",
        "path_names"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A2_D2_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A4_D2_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A6_D2_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A8_D2_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A10_D2_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A12_D2_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A2_D3_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A4_D3_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A6_D3_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A8_D3_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A10_D3_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A12_D3_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A2_D4_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A4_D4_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A6_D4_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A8_D4_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A10_D4_xr_Dataset.nc',\n",
              " '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/netcdf_files/Pain/A12_D4_xr_Dataset.nc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "Wh73dobhnmRw",
        "colab_type": "code",
        "outputId": "c133b79f-1083-4993-ba1b-a16dc96f7383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1335
        }
      },
      "cell_type": "code",
      "source": [
        "### may have to update int(animal_number)\n",
        "\n",
        "order = 'animal'\n",
        "size_random = 15\n",
        "session_name = 'pain'\n",
        "save_path = '/content/gdrive/Team Drives/USV_eScience_Incubator/Data/feature_data_frames'\n",
        "\n",
        "annot_features_yes_psd = pd.DataFrame()\n",
        "annot_features_no_psd = pd.DataFrame()\n",
        "\n",
        "for path in path_names:\n",
        "    \n",
        "    annot_yes, annot_no = create_annotation_slice_psds(path, order, annot_data, size_random)\n",
        "    \n",
        "    annot_features_yes_psd = annot_features_yes_psd.append(annot_yes, ignore_index=True)\n",
        "    annot_features_no_psd = annot_features_no_psd.append(annot_no, ignore_index=True)\n",
        "\n",
        "#create and save combined dataframe of yes and no\n",
        "annot_features_yes_psd.drop(['Unnamed: 0', 'High Freq (Hz)'], axis=1, inplace=True)\n",
        "annot_features_full_psd = pd.concat([annot_features_yes_psd, annot_features_no_psd])\n",
        "print(annot_features_full_psd.shape)\n",
        "print(annot_features_full_psd.Annotation.value_counts())\n",
        "\n",
        "annot_features_full_psd.to_csv(str(save_path + '/annot_features_full_' + 'psd_' + session_name + '_new.csv'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A2 D2\n",
            "A2 D2\n",
            "(13333,)\n",
            "13333\n",
            "A4 D2\n",
            "A4 D2\n",
            "(13333,)\n",
            "13333\n",
            "A6 D2\n",
            "A6 D2\n",
            "(13333,)\n",
            "13333\n",
            "A8 D2\n",
            "A8 D2\n",
            "(13333,)\n",
            "13333\n",
            "A10 D2\n",
            "A10 D2\n",
            "(13333,)\n",
            "13333\n",
            "A12 D2\n",
            "A12 D2\n",
            "(13333,)\n",
            "13333\n",
            "A2 D3\n",
            "A2 D3\n",
            "(13333,)\n",
            "13333\n",
            "A4 D3\n",
            "A4 D3\n",
            "(13333,)\n",
            "13333\n",
            "A6 D3\n",
            "A6 D3\n",
            "(13333,)\n",
            "13333\n",
            "A8 D3\n",
            "A8 D3\n",
            "(13333,)\n",
            "13333\n",
            "A10 D3\n",
            "A10 D3\n",
            "(13333,)\n",
            "13333\n",
            "A12 D3\n",
            "A12 D3\n",
            "(13333,)\n",
            "13333\n",
            "A2 D4\n",
            "A2 D4\n",
            "(13333,)\n",
            "13333\n",
            "A4 D4\n",
            "A4 D4\n",
            "(13333,)\n",
            "13333\n",
            "A6 D4\n",
            "A6 D4\n",
            "(13333,)\n",
            "13333\n",
            "A8 D4\n",
            "A8 D4\n",
            "(13333,)\n",
            "13333\n",
            "A10 D4\n",
            "A10 D4\n",
            "(13333,)\n",
            "13333\n",
            "A12 D4\n",
            "A12 D4\n",
            "(13333,)\n",
            "13333\n",
            "(448, 261)\n",
            "rand_noise    270\n",
            "BBC           178\n",
            "Name: Annotation, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}